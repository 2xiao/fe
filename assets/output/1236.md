# [1236. 网络爬虫 🔒](https://2xiao.github.io/leetcode-js/problem/1236.html)

🟠 <font color=#ffb800>Medium</font>&emsp; 🔖&ensp; [`深度优先搜索`](/tag/depth-first-search.md) [`广度优先搜索`](/tag/breadth-first-search.md) [`字符串`](/tag/string.md) [`交互`](/tag/interactive.md)&emsp; 🔗&ensp;[`力扣`](https://leetcode.cn/problems/web-crawler) [`LeetCode`](https://leetcode.com/problems/web-crawler)

## 题目

Given a url `startUrl` and an interface `HtmlParser`, implement a web crawler
to crawl all links that are under the **same hostname** as `startUrl`.

Return all urls obtained by your web crawler in **any** order.

Your crawler should:

  * Start from the page: `startUrl`
  * Call `HtmlParser.getUrls(url)` to get all urls from a webpage of given url.
  * Do not crawl the same link twice.
  * Explore only the links that are under the **same hostname** as `startUrl`.

![](https://fastly.jsdelivr.net/gh/doocs/leetcode@main/solution/1200-1299/1236.Web%20Crawler/images/urlhostname.png)

As shown in the example url above, the hostname is `example.org`. For
simplicity sake, you may assume all urls use **http protocol** without any
**port** specified. For example, the urls `http://leetcode.com/problems` and
`http://leetcode.com/contest` are under the same hostname, while urls
`http://example.org/test` and `http://example.com/abc` are not under the same
hostname.

The `HtmlParser` interface is defined as such:

> 
> 
> 
> 
> 
> interface HtmlParser {
> 
>   // Return a list of all urls from a webpage of given _url_.
> 
>   public List<String> getUrls(String url);
> 
> }

Below are two examples explaining the functionality of the problem, for custom
testing purposes you'll have three variables `urls`, `edges` and `startUrl`.
Notice that you will only have access to `startUrl` in your code, while `urls`
and `edges` are not directly accessible to you in code.

Note: Consider the same URL with the trailing slash "/" as a different URL.
For example, "http://news.yahoo.com", and "http://news.yahoo.com/" are
different urls.



**Example 1:**

![](https://fastly.jsdelivr.net/gh/doocs/leetcode@main/solution/1200-1299/1236.Web%20Crawler/images/sample_2_1497.png)

> Input: urls = [
> 
>   "http://news.yahoo.com",
> 
>   "http://news.yahoo.com/news",
> 
>   "http://news.yahoo.com/news/topics/",
> 
>   "http://news.google.com",
> 
>   "http://news.yahoo.com/us"
> 
> ]
> 
> edges = [[2,0],[2,1],[3,2],[3,1],[0,4]]
> 
> startUrl = "http://news.yahoo.com/news/topics/"
> 
> Output: [
> 
>   "http://news.yahoo.com",
> 
>   "http://news.yahoo.com/news",
> 
>   "http://news.yahoo.com/news/topics/",
> 
>   "http://news.yahoo.com/us"
> 
> ]

**Example 2:**

**![](https://fastly.jsdelivr.net/gh/doocs/leetcode@main/solution/1200-1299/1236.Web%20Crawler/images/sample_3_1497.png)**

> Input: 
> 
> urls = [
> 
>   "http://news.yahoo.com",
> 
>   "http://news.yahoo.com/news",
> 
>   "http://news.yahoo.com/news/topics/",
> 
>   "http://news.google.com"
> 
> ]
> 
> edges = [[0,2],[2,1],[3,2],[3,1],[3,0]]
> 
> startUrl = "http://news.google.com"
> 
> Output: ["http://news.google.com"]
> 
> Explanation: The startUrl links to all other pages that do not share the same hostname.



**Constraints:**

  * `1 <= urls.length <= 1000`
  * `1 <= urls[i].length <= 300`
  * `startUrl` is one of the `urls`.
  * Hostname label must be from 1 to 63 characters long, including the dots, may contain only the ASCII letters from 'a' to 'z', digits  from '0' to '9' and the hyphen-minus character ('-').
  * The hostname may not start or end with the hyphen-minus character ('-'). 
  * See:  <https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames>
  * You may assume there're no duplicates in url library.


## 题目大意

给定一个链接 `startUrl` 和一个接口 `HtmlParser` ，请你实现一个网络爬虫，以实现爬取同 `startUrl` 拥有相同 **主机名
**的全部链接。

该爬虫得到的全部链接可以 **任何顺序  **返回结果。

你的网络爬虫应当按照如下模式工作：

  * 自链接 `startUrl` 开始爬取
  * 调用 `HtmlParser.getUrls(url)` 来获得链接`url`页面中的全部链接
  * 同一个链接最多只爬取一次
  * 只输出 **域名  **与** **`startUrl` **相同  **的链接集合

![](https://fastly.jsdelivr.net/gh/doocs/leetcode@main/solution/1200-1299/1236.Web%20Crawler/images/urlhostname.png)

如上所示的一个链接，其域名为 `example.org`。简单起见，你可以假设所有的链接都采用 **http协议  **并没有指定 **端口**
。例如，链接 `http://leetcode.com/problems` 和 `http://leetcode.com/contest`
是同一个域名下的，而链接 `http://example.org/test` 和 `http://example.com/abc` 是不在同一域名下的。

`HtmlParser` 接口定义如下：

> 
> 
> 
> 
> 
> interface HtmlParser {
> 
>   // 返回给定 url 对应的页面中的全部 url 。
> 
>   public List<String> getUrls(String url);
> 
> }

下面是两个实例，用以解释该问题的设计功能，对于自定义测试，你可以使用三个变量  `urls`, `edges` 和
`startUrl`。注意在代码实现中，你只可以访问 `startUrl` ，而 `urls` 和 `edges` 不可以在你的代码中被直接访问。

注意：将尾随斜线“/”的相同 URL 视为不同的 URL。例如，“http://news.yahoo.com” 和
“http://news.yahoo.com/” 是不同的域名。



**示例 1：**

![](https://fastly.jsdelivr.net/gh/doocs/leetcode@main/solution/1200-1299/1236.Web%20Crawler/images/sample_2_1497.png)

> 
> 
> 
> 
> 
> **输入：** urls = [
> 
>   "http://news.yahoo.com",
> 
>   "http://news.yahoo.com/news",
> 
>   "http://news.yahoo.com/news/topics/",
> 
>   "http://news.google.com",
> 
>   "http://news.yahoo.com/us"
> 
> ]
> 
> edges = [[2,0],[2,1],[3,2],[3,1],[0,4]]
> 
> startUrl = "http://news.yahoo.com/news/topics/"
> 
> **输出：**[
> 
>   "http://news.yahoo.com",
> 
>   "http://news.yahoo.com/news",
> 
>   "http://news.yahoo.com/news/topics/",
> 
>   "http://news.yahoo.com/us"
> 
> ]
> 
> 

**示例 2：**

**![](https://fastly.jsdelivr.net/gh/doocs/leetcode@main/solution/1200-1299/1236.Web%20Crawler/images/sample_3_1497.png)**

> 
> 
> 
> 
> 
> **输入：**
> 
> urls = [
> 
>   "http://news.yahoo.com",
> 
>   "http://news.yahoo.com/news",
> 
>   "http://news.yahoo.com/news/topics/",
> 
>   "http://news.google.com"
> 
> ]
> 
> edges = [[0,2],[2,1],[3,2],[3,1],[3,0]]
> 
> startUrl = "http://news.google.com"
> 
> **输出：**["http://news.google.com"]
> 
> **解释：** startUrl 链接到所有其他不共享相同主机名的页面。



**提示：**

  * `1 <= urls.length <= 1000`
  * `1 <= urls[i].length <= 300`
  * `startUrl` 为 `urls` 中的一个。
  * 主机名的长为1到63个字符（包括点），只能包含从‘a’到‘z’的ASCII字母、‘0’到‘9’的数字以及连字符即减号（‘-’）。
  * 主机名不会以连字符即减号（‘-’）开头或结尾。
  * 关于域名有效性的约束可参考:  <https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames>
  * 你可以假定url库中不包含重复项。


## 解题思路

#### 复杂度分析

- **时间复杂度**：`O()`，
- **空间复杂度**：`O()`，

## 代码

```javascript

```

## 相关题目

<!-- prettier-ignore -->
| 题号 | 标题 | 题解 | 标签 | 难度 |
| :------: | :------ | :------: | :------ | :------ |
| 1242 | [多线程网页爬虫 🔒](https://leetcode.com/problems/web-crawler-multithreaded) |  |  [`深度优先搜索`](/tag/depth-first-search.md) [`广度优先搜索`](/tag/breadth-first-search.md) [`多线程`](/tag/concurrency.md) | <font color=#ffb800>Medium</font> |